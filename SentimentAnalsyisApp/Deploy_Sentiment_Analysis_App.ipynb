{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 65499 entries, 0 to 65498\n",
      "Data columns (total 7 columns):\n",
      "ItemID             65499 non-null int64\n",
      "Sentiment          65499 non-null int64\n",
      "SentimentSource    65499 non-null object\n",
      "SentimentText      65499 non-null object\n",
      "Unnamed: 4         0 non-null float64\n",
      "Unnamed: 5         0 non-null float64\n",
      "Unnamed: 6         0 non-null float64\n",
      "dtypes: float64(3), int64(2), object(2)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_tweets = pd.read_csv(\"twitter_sentiments.csv\")\n",
    "df_tweets.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment SentimentSource  \\\n",
       "0       1          0    Sentiment140   \n",
       "1       2          0    Sentiment140   \n",
       "2       3          1    Sentiment140   \n",
       "\n",
       "                                       SentimentText  Unnamed: 4  Unnamed: 5  \\\n",
       "0                       is so sad for my APL frie...         NaN         NaN   \n",
       "1                     I missed the New Moon trail...         NaN         NaN   \n",
       "2                            omg its already 7:30 :O         NaN         NaN   \n",
       "\n",
       "   Unnamed: 6  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_tweets[\"SentimentSource\"]\n",
    "del df_tweets[\"Unnamed: 4\"]\n",
    "del df_tweets[\"Unnamed: 5\"]\n",
    "del df_tweets[\"Unnamed: 6\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment                                      SentimentText\n",
       "0       1          0                       is so sad for my APL frie...\n",
       "1       2          0                     I missed the New Moon trail...\n",
       "2       3          1                            omg its already 7:30 :O\n",
       "3       4          0  .. Omgaga. Im sooo  im gunna CRy. I've been at...\n",
       "4       5          0           i think mi bf is cheating on me!!!   ..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Juuuuuuuuuuuuuuuuussssst Chillin!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>handed in my uniform today . i miss you already</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hmmmm.... i wonder how she my number @-)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>thanks to all the haters up in my face all day! 112-102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              SentimentText  Sentiment\n",
       "2                                   omg its already 7:30 :O          1\n",
       "6                        Juuuuuuuuuuuuuuuuussssst Chillin!!          1\n",
       "8           handed in my uniform today . i miss you already          1\n",
       "9                  hmmmm.... i wonder how she my number @-)          1\n",
       "11  thanks to all the haters up in my face all day! 112-102          1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets[df_tweets[\"Sentiment\"] == 1][[\"SentimentText\",\"Sentiment\"]].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>is so sad for my APL friend.............</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I missed the New Moon trailer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i think mi bf is cheating on me!!!       T_T</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>or i just worry too much?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                         SentimentText  \\\n",
       "0                                                             is so sad for my APL friend.............   \n",
       "1                                                                     I missed the New Moon trailer...   \n",
       "3  .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get ...   \n",
       "4                                                         i think mi bf is cheating on me!!!       T_T   \n",
       "5                                                                    or i just worry too much?           \n",
       "\n",
       "   Sentiment  \n",
       "0          0  \n",
       "1          0  \n",
       "3          0  \n",
       "4          0  \n",
       "5          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets[df_tweets[\"Sentiment\"] == 0][[\"SentimentText\",\"Sentiment\"]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to lower case\n",
    "df_tweets['clean_tweet'] = df_tweets['SentimentText'].str.lower()\n",
    "# Remove punctuations\n",
    "df_tweets['clean_tweet'] = df_tweets['clean_tweet'].str.replace('[^\\w\\s]',' ')\n",
    "# Remove spaces in between words\n",
    "df_tweets['clean_tweet'] = df_tweets['clean_tweet'].str.replace(' +', ' ')\n",
    "# Remove Numbers\n",
    "df_tweets['clean_tweet'] = df_tweets['clean_tweet'].str.replace('\\d+', '')\n",
    "# Remove trailing spaces\n",
    "df_tweets['clean_tweet'] = df_tweets['clean_tweet'].str.strip()\n",
    "# Remove URLS\n",
    "df_tweets['clean_tweet'] = df_tweets['clean_tweet'].apply(lambda x: re.split('https:\\/\\/.*', str(x))[0])\n",
    "# remove stop words\n",
    "stop = stopwords.words('english')\n",
    "stop.extend([\"racism\",\"alllivesmatter\",\"amp\",\"https\",\"co\",\"like\",\"people\",\"black\",\"white\"])\n",
    "df_tweets['clean_tweet'] =  df_tweets['clean_tweet'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>is so sad for my APL friend.............</td>\n",
       "      <td>sad apl friend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>I missed the New Moon trailer...</td>\n",
       "      <td>missed new moon trailer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>omg already</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get ...</td>\n",
       "      <td>omgaga im sooo im gunna cry dentist since suposed get crown put mins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>i think mi bf is cheating on me!!!       T_T</td>\n",
       "      <td>think mi bf cheating t_t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment  \\\n",
       "0       1          0   \n",
       "1       2          0   \n",
       "2       3          1   \n",
       "3       4          0   \n",
       "4       5          0   \n",
       "\n",
       "                                                                                         SentimentText  \\\n",
       "0                                                             is so sad for my APL friend.............   \n",
       "1                                                                     I missed the New Moon trailer...   \n",
       "2                                                                              omg its already 7:30 :O   \n",
       "3  .. Omgaga. Im sooo  im gunna CRy. I've been at this dentist since 11.. I was suposed 2 just get ...   \n",
       "4                                                         i think mi bf is cheating on me!!!       T_T   \n",
       "\n",
       "                                                            clean_tweet  \n",
       "0                                                        sad apl friend  \n",
       "1                                               missed new moon trailer  \n",
       "2                                                           omg already  \n",
       "3  omgaga im sooo im gunna cry dentist since suposed get crown put mins  \n",
       "4                                              think mi bf cheating t_t  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a1be444a8>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tweets.Sentiment.value_counts().plot(\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(52399, 4) (13100, 4)\n"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "df_train, df_test = train_test_split(df_tweets, test_size = 0.2, stratify = df_tweets['Sentiment'], random_state=21)\n",
    "\n",
    "# get the shape of train and test split.\n",
    "print(df_train.shape, df_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TF-IDF Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=frozenset({'side', 'whereupon', 'under', 'twenty', 'with', 'nobody', 'something', 'whenever', 'afterwards', 'indeed', 'since', 'themselves', 'while', 'on', 'whatever', 'name', 'becoming', 'back', 'whither', 'become', 'meanwhile', 'eg', 'us', 'put', 'same', 'hasnt', 'otherwise', 'everywher...lve', 'so', 'fifteen', 'will', 'mine', 'elsewhere', 'your', 'alone', 'mill', 'already', 'describe'}),\n",
       "        strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
       "        vocabulary=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a TF-IDF vectorizer object\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase= True, max_features=1000, stop_words=ENGLISH_STOP_WORDS)\n",
    "\n",
    "# fit the object with the training data tweets\n",
    "tfidf_vectorizer.fit(df_train.clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the train and test data\n",
    "train_idf = tfidf_vectorizer.transform(df_train.clean_tweet)\n",
    "test_idf  = tfidf_vectorizer.transform(df_test.clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<52399x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 189442 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oindrilasen/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7756614274755586\n",
      "0.7609870434273065\n"
     ]
    }
   ],
   "source": [
    "# create the object of Logistic Regression Model\n",
    "model_LR = LogisticRegression()\n",
    "\n",
    "# fit the model with the training data\n",
    "model_LR.fit(train_idf, df_train.Sentiment)\n",
    "\n",
    "# predict the label on the traning data\n",
    "predict_train = model_LR.predict(train_idf)\n",
    "\n",
    "# predict the model on the test data\n",
    "predict_test = model_LR.predict(test_idf)\n",
    "\n",
    "# f1 score on train data\n",
    "print(f1_score(y_true= df_train.Sentiment, y_pred= predict_train))\n",
    "\n",
    "\n",
    "print(f1_score(y_true= df_test.Sentiment, y_pred= predict_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9439373745212829\n",
      "0.7446455805317951\n"
     ]
    }
   ],
   "source": [
    "# create the object of Random Forest Model\n",
    "model_RF = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# fit the model with the training data\n",
    "model_RF.fit(train_idf, df_train.Sentiment)\n",
    "\n",
    "# predict the label on the traning data\n",
    "predict_train = model_RF.predict(train_idf)\n",
    "\n",
    "# predict the model on the test data\n",
    "predict_test = model_RF.predict(test_idf)\n",
    "\n",
    "# f1 score on train data\n",
    "print(f1_score(y_true= df_train.Sentiment, y_pred= predict_train))\n",
    "\n",
    "\n",
    "print(f1_score(y_true= df_test.Sentiment, y_pred= predict_test))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Pipeline Stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=1000, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps= [('tfidf', TfidfVectorizer(lowercase=True,\n",
    "                                                      max_features=1000,\n",
    "                                                      stop_words= ENGLISH_STOP_WORDS)),\n",
    "                            ('model', RandomForestClassifier(n_estimators = 100))])\n",
    "\n",
    "# fit the pipeline model with the training data                            \n",
    "pipeline.fit(df_train.clean_tweet, df_train.Sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump the Pipeline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_classification.joblib']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib\n",
    "from joblib import dump\n",
    "\n",
    "# dump the pipeline model\n",
    "dump(pipeline, filename=\"text_classification.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import joblib\n",
    "from joblib import load\n",
    "\n",
    "# sample tweet text\n",
    "text = [\"The IRS estimates that undocumented immigrants pay over $9 billion in withheld payroll taxes annually.Yes #DonaldTrump please continue your conversation about these caravans full of leeches just trying to take our hard earned money...#TrumpTaxReturns #Trump750 #MondayMorning\"]\n",
    "\n",
    "# load the saved pipleine model\n",
    "pipeline = load(\"text_classification.joblib\")\n",
    "\n",
    "# predict on the sample tweet text\n",
    "pipeline.predict(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample tweet\n",
    "text = [\"Nevada / Las Vegas: Come join me tonight at Pahrump Winery for a #MAGA event in support of @realDonaldTrump! Doors open at 4pm. Letâ€™s #KeepAmericaGreat #TeamTrump\"]\n",
    "# predict the label using the pipeline\n",
    "pipeline.predict(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect Twitter and search for a Keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import config\n",
    "    \n",
    "# initialize api instance\\n\n",
    "consumer_key= config.consumer_key\n",
    "consumer_secret= config.consumer_secret\n",
    "access_token=config.access_token\n",
    "access_token_secret =config.access_token_secret\n",
    "\n",
    "#Connect to Twitter through the API\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret) \n",
    "api = tweepy.API(auth,wait_on_rate_limit=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_tweets(search_keyword):\n",
    "    ''' collect tweets '''\n",
    "    try: \n",
    "        count = 50\n",
    "        # Create Blank Dataframe\\n\",\n",
    "        df_tweets = pd.DataFrame(pd.np.empty((0, 1)))\n",
    "        for keyword in search_keyword:\n",
    "            # Remove Retweets\n",
    "            search_tag = keyword +  \"-filter:retweets\" +  \"-filter:media\"\n",
    "            \n",
    "            print('Searching tweets for: ', search_tag)\n",
    "    \n",
    "            fetched_tweets = tweepy.Cursor(api.search,\n",
    "                                q=search_tag,\n",
    "                                lang=\"en\").items(50)\n",
    "            # Add records to the dataframe\n",
    "            df_tweets = df_tweets.append([[tweet.text] for tweet in fetched_tweets])\n",
    "            # Add columns\n",
    "            df_tweets.columns = ['tweets']\n",
    "            #clean emojis and pictures from tweets\n",
    "            df_tweets['tweets'] = df_tweets['tweets'].str.replace(r'[^\\x00-\\x7F]+', '', regex=True)\n",
    "            # Retuen Data\n",
    "            return(df_tweets)\n",
    "    except Exception as e:\n",
    "        print('Encountered Exception:', e)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test The Model for a hashtag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching tweets for:  #-filter:retweets-filter:media\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @chioma_mmeje: Police tried to arrest one guy at the #AbujaProtests. Everyone formed barricad...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RT @athie_gnome: @apark2453 Yet again: people simply cannot believe that the 1A is as strong as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@KameaChayne He gave a series of interview over the last 2 years where he says it</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @jbrialarae: if we link AGAIN, you won.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @AloneJust_me: @scenesofriends is my grandpa too https://t.co/cJJkKdjTtZ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@wetzelart interesting</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@_nishav Okay thank you!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @squishyjinki: Kibums cover of Taemins Criminal https://t.co/XdGci3Q6BO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @stfudanie14: PINOY CHEESE STICK https://t.co/upTUSfC6oQ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'@BLACKPINK: Light Up The Sky' Is An Unguarded Look Into The World's Biggest Girl Group #blackpi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @sementric: Dear @saranichollsCAN &amp;amp; @CanHCGhana I woke up to say my Thanksgiving prayer f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RT @rajhanse2: @buitengebieden_ @RV_27 https://t.co/FXo4jOliLm and meet two another  friends</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RT @RedRum_49: He just made my whole day and my first order thank you bro https://t.co/VTVfwsmMJh</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@AmityShlaes Mighty like God.....or Mammon?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RT @temisrael007: Thank you @seyiamakinde for allowing us express our civil right to protest wit...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@courtney7593 @bennettschi Democrats got 3 times as much as republicans!! Nearly 1 billion chew ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RT @kpophappenings_: when that kpop boy used his black card on a vending machine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RT @whitneyhasaplan: Nope! This aint what we been out in the sun and rain for, for days. \\n\\nWe ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RT @DEADLINE: Bruce Springsteen &amp;amp; Don Winslow Team On Video Just In Time For President Trump...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RT @PrescotCablesFC: Your Pesky Bulls to take on City of Liverpool at the @IPTruckpartsLtd Stadi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                 tweets  \\\n",
       "0   RT @chioma_mmeje: Police tried to arrest one guy at the #AbujaProtests. Everyone formed barricad...   \n",
       "1   RT @athie_gnome: @apark2453 Yet again: people simply cannot believe that the 1A is as strong as ...   \n",
       "2                     @KameaChayne He gave a series of interview over the last 2 years where he says it   \n",
       "3                                                            RT @jbrialarae: if we link AGAIN, you won.   \n",
       "4                           RT @AloneJust_me: @scenesofriends is my grandpa too https://t.co/cJJkKdjTtZ   \n",
       "5                                                                                @wetzelart interesting   \n",
       "6                                                                              @_nishav Okay thank you!   \n",
       "7                            RT @squishyjinki: Kibums cover of Taemins Criminal https://t.co/XdGci3Q6BO   \n",
       "8                                           RT @stfudanie14: PINOY CHEESE STICK https://t.co/upTUSfC6oQ   \n",
       "9   '@BLACKPINK: Light Up The Sky' Is An Unguarded Look Into The World's Biggest Girl Group #blackpi...   \n",
       "10  RT @sementric: Dear @saranichollsCAN &amp; @CanHCGhana I woke up to say my Thanksgiving prayer f...   \n",
       "11         RT @rajhanse2: @buitengebieden_ @RV_27 https://t.co/FXo4jOliLm and meet two another  friends   \n",
       "12    RT @RedRum_49: He just made my whole day and my first order thank you bro https://t.co/VTVfwsmMJh   \n",
       "13                                                          @AmityShlaes Mighty like God.....or Mammon?   \n",
       "14  RT @temisrael007: Thank you @seyiamakinde for allowing us express our civil right to protest wit...   \n",
       "15  @courtney7593 @bennettschi Democrats got 3 times as much as republicans!! Nearly 1 billion chew ...   \n",
       "16                     RT @kpophappenings_: when that kpop boy used his black card on a vending machine   \n",
       "17  RT @whitneyhasaplan: Nope! This aint what we been out in the sun and rain for, for days. \\n\\nWe ...   \n",
       "18  RT @DEADLINE: Bruce Springsteen &amp; Don Winslow Team On Video Just In Time For President Trump...   \n",
       "19  RT @PrescotCablesFC: Your Pesky Bulls to take on City of Liverpool at the @IPTruckpartsLtd Stadi...   \n",
       "\n",
       "    prediction  \n",
       "0            0  \n",
       "1            1  \n",
       "2            1  \n",
       "3            0  \n",
       "4            1  \n",
       "5            1  \n",
       "6            1  \n",
       "7            0  \n",
       "8            0  \n",
       "9            1  \n",
       "10           0  \n",
       "11           1  \n",
       "12           1  \n",
       "13           1  \n",
       "14           1  \n",
       "15           1  \n",
       "16           0  \n",
       "17           0  \n",
       "18           0  \n",
       "19           1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "tweets = get_related_tweets(\"#USElection2020\")\n",
    "# get the prediction\n",
    "tweets['prediction'] = pipeline.predict(tweets['tweets'])\n",
    "tweets.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect webpage and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "from flask import Flask, render_template, request, redirect, url_for\n",
    "from joblib import load\n",
    "#from get_tweets import get_related_tweets\n",
    "\n",
    "\n",
    "# load the pipeline object\n",
    "pipeline = load(\"text_classification.joblib\")\n",
    "\n",
    "# function to get results for a particular text query\n",
    "def requestResults(search_keyword):\n",
    "    # get the tweets text\n",
    "    tweets = get_related_tweets(search_keyword)\n",
    "    # get the prediction\n",
    "    tweets['prediction'] = pipeline.predict(tweets['tweets'])\n",
    "    # get the value counts of different labels predicted\n",
    "    data = str(tweets.prediction.value_counts()) + '\\n\\n'\n",
    "    return data + str(tweets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start flask\n",
    "app = Flask(__name__)\n",
    "\n",
    "# render default webpage\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('home.html')\n",
    "\n",
    "# when the post method detect, then redirect to success function\n",
    "@app.route('/', methods=['POST', 'GET'])\n",
    "def get_data():\n",
    "    if request.method == 'POST':\n",
    "        user = request.form['search']\n",
    "        return redirect(url_for('success', name=user))\n",
    "\n",
    "# get the data for the requested query\n",
    "@app.route('/success/<name>')\n",
    "def success(name):\n",
    "    return \"<xmp>\" + str(requestResults(name)) + \" </xmp> \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: Do not use the development server in a production environment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [13/Oct/2020 11:29:35] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [13/Oct/2020 11:29:53] \"POST / HTTP/1.1\" 302 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching tweets for:  #-filter:retweets-filter:media\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [13/Oct/2020 11:29:56] \"GET /success/%23USElection2020 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    import random, threading, webbrowser\n",
    "\n",
    "    #port = 5000 + random.randint(0, 999)\n",
    "    #print(port)\n",
    "    #url = \"http://127.0.0.1:{0}\".format(port)\n",
    "    app.run(use_reloader=False, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
