{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goodreads Data Wrangling and Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will do the below steps:\n",
    "1. Connect to the Database and Fetch Data and create a Pandas Dataframe for further analysis\n",
    "2. Data Wrangling to clean and tranform the data\n",
    "3. Feature Extraction to get some new useful features for building a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Fetch Data from Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/oindrilasen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "# Data wrangling\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize \n",
    "from textblob import Word\n",
    "from nltk.probability import FreqDist\n",
    "#from textblob import TextBlob\n",
    "st = PorterStemmer()\n",
    "nltk.download('stopwords')\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Connect to the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sqlite3.Connection object at 0x1a18f539d0>\n",
      "<sqlite3.Cursor object at 0x1a18fc7420>\n"
     ]
    }
   ],
   "source": [
    "conn = sqlite3.connect('/Users/oindrilasen/Notebooks/CapstoneProject1/Final/goodreads_db.db.sqlite')\n",
    "cur = conn.cursor()\n",
    "print(conn)\n",
    "print(cur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Fetch Data from Database into pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records and Columns in Books DF:  (9576, 11)\n",
      "Records and Columns in Authors DF:  (9576, 9)\n"
     ]
    }
   ],
   "source": [
    "df_books = pd.read_sql_query(\"select * from books order by book_id\",conn)\n",
    "df_authors = pd.read_sql_query(\"select * from authors order by book_id\",conn)\n",
    "print(\"Records and Columns in Books DF: \",df_books.shape)\n",
    "print(\"Records and Columns in Authors DF: \",df_authors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Merge the books and authora data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Records and Features:  (9576, 19)\n"
     ]
    }
   ],
   "source": [
    "df_details = pd.merge(df_books, df_authors)\n",
    "print(\"Total Records and Features: \",df_details.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Explore Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9576 entries, 0 to 9575\n",
      "Data columns (total 19 columns):\n",
      "book_id             9576 non-null int64\n",
      "isbn                7864 non-null object\n",
      "title               9576 non-null object\n",
      "total_pages         8848 non-null float64\n",
      "average_rating      9576 non-null float64\n",
      "ratings_count       9576 non-null int64\n",
      "reviews_count       9576 non-null int64\n",
      "publication_date    8029 non-null object\n",
      "publisher           8521 non-null object\n",
      "popular_shelves     8029 non-null object\n",
      "book_description    9370 non-null object\n",
      "author_id           9576 non-null int64\n",
      "author_name         9576 non-null object\n",
      "birth_on            3482 non-null object\n",
      "death_on            1201 non-null object\n",
      "fans_count          9576 non-null int64\n",
      "gender              8321 non-null object\n",
      "hometown            5729 non-null object\n",
      "works_count         9576 non-null int64\n",
      "dtypes: float64(2), int64(6), object(11)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_details.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_id</th>\n",
       "      <th>isbn</th>\n",
       "      <th>title</th>\n",
       "      <th>total_pages</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>reviews_count</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>publisher</th>\n",
       "      <th>popular_shelves</th>\n",
       "      <th>book_description</th>\n",
       "      <th>author_id</th>\n",
       "      <th>author_name</th>\n",
       "      <th>birth_on</th>\n",
       "      <th>death_on</th>\n",
       "      <th>fans_count</th>\n",
       "      <th>gender</th>\n",
       "      <th>hometown</th>\n",
       "      <th>works_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0439785960</td>\n",
       "      <td>Harry Potter and the Half-Blood Prince (Harry ...</td>\n",
       "      <td>652.0</td>\n",
       "      <td>4.56</td>\n",
       "      <td>1940880</td>\n",
       "      <td>26187</td>\n",
       "      <td>9,16,2006</td>\n",
       "      <td>Scholastic Inc.</td>\n",
       "      <td>to-read,fantasy,favorites,currently-reading,yo...</td>\n",
       "      <td>When Harry Potter and the Half-Blood Prince op...</td>\n",
       "      <td>1077326</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>1965/07/31</td>\n",
       "      <td>None</td>\n",
       "      <td>198576</td>\n",
       "      <td>female</td>\n",
       "      <td>Yate, South Gloucestershire, England</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0439358078</td>\n",
       "      <td>Harry Potter and the Order of the Phoenix (Har...</td>\n",
       "      <td>870.0</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1993215</td>\n",
       "      <td>27553</td>\n",
       "      <td>9,1,2004</td>\n",
       "      <td>Scholastic Inc.</td>\n",
       "      <td>to-read,fantasy,favorites,currently-reading,yo...</td>\n",
       "      <td>There is a door at the end of a silent corrido...</td>\n",
       "      <td>1077326</td>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>1965/07/31</td>\n",
       "      <td>None</td>\n",
       "      <td>198576</td>\n",
       "      <td>female</td>\n",
       "      <td>Yate, South Gloucestershire, England</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   book_id        isbn                                              title  \\\n",
       "0        1  0439785960  Harry Potter and the Half-Blood Prince (Harry ...   \n",
       "1        2  0439358078  Harry Potter and the Order of the Phoenix (Har...   \n",
       "\n",
       "   total_pages  average_rating  ratings_count  reviews_count publication_date  \\\n",
       "0        652.0            4.56        1940880          26187        9,16,2006   \n",
       "1        870.0            4.49        1993215          27553         9,1,2004   \n",
       "\n",
       "         publisher                                    popular_shelves  \\\n",
       "0  Scholastic Inc.  to-read,fantasy,favorites,currently-reading,yo...   \n",
       "1  Scholastic Inc.  to-read,fantasy,favorites,currently-reading,yo...   \n",
       "\n",
       "                                    book_description  author_id   author_name  \\\n",
       "0  When Harry Potter and the Half-Blood Prince op...    1077326  J.K. Rowling   \n",
       "1  There is a door at the end of a silent corrido...    1077326  J.K. Rowling   \n",
       "\n",
       "     birth_on death_on  fans_count  gender  \\\n",
       "0  1965/07/31     None      198576  female   \n",
       "1  1965/07/31     None      198576  female   \n",
       "\n",
       "                               hometown  works_count  \n",
       "0  Yate, South Gloucestershire, England          191  \n",
       "1  Yate, South Gloucestershire, England          191  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_details.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step2: Data Wrangling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Convert the Gender column to category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details.gender=df_details.gender.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Convert the Date columns to Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details['birth_on'] = pd.to_datetime(df_details[\"birth_on\"].str.strip(), format='%Y/%m/%d',errors='coerce')\n",
    "df_details['death_on'] = pd.to_datetime(df_details[\"death_on\"].str.strip(), format='%Y/%m/%d', errors='coerce')\n",
    "df_details['publication_date'] = pd.to_datetime(df_details['publication_date'].str.strip(), format='%m,%d,%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Check for NULL columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "book_id                0\n",
       "isbn                1712\n",
       "title                  0\n",
       "total_pages          728\n",
       "average_rating         0\n",
       "ratings_count          0\n",
       "reviews_count          0\n",
       "publication_date    1547\n",
       "publisher           1055\n",
       "popular_shelves     1547\n",
       "book_description     206\n",
       "author_id              0\n",
       "author_name            0\n",
       "birth_on            6104\n",
       "death_on            8382\n",
       "fans_count             0\n",
       "gender              1255\n",
       "hometown            3847\n",
       "works_count            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_details.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing data for total_pages\n",
    "df_details[\"total_pages\"] = df_details[\"total_pages\"].fillna(round(df_details[\"total_pages\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing data for fans_count\n",
    "df_details[\"fans_count\"] = df_details[\"fans_count\"].fillna(round(df_details[\"fans_count\"].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing data for popular_shelves\n",
    "df_details['popular_shelves'] = df_details['popular_shelves'].fillna(\"No_Tags\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing data for gender\n",
    "df_details[\"gender\"] = df_details[\"gender\"].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing data for book_description\n",
    "df_details[\"book_description\"] = df_details[\"book_description\"].fillna(\"No_Description\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Fetch popular tags for books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert the series to list\n",
    "shelves = df_details[\"popular_shelves\"].values.tolist()\n",
    "# Join all the tags\n",
    "#shelves = ','.join(filter(None,shelves))\n",
    "shelves = ','.join(shelves)\n",
    "shelves = shelves.split(\",\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude NOT-SO-VALID Tags\n",
    "exclude_item = ['fiction-fantasy','literature','science-fiction','science_fantasy','fiction','sciencefiction','science-fiction','sf','sci-fi','scifi','sff','science','to-read-sci-fi',\n",
    "                'to-read','currently-reading','unread','read-in-2011','read-in-2012','read-in-2014','read-in-2015',\n",
    "                'read-2016','read-in-2016','read-in-2017','read-in-2018','to-read-scifi','general-fiction','classic-sci-fi',\n",
    "                're-read','not-read','reviewed','owned-but-not-read','to-read-fiction','genre-science-fiction',\n",
    "                'owned','favorites','library','books-i-own','owned-books','to-buy','own-it','i-own','home-library','bookshelf',\n",
    "                'novels','my-library','wish-list','books','my-books','default','have','favourites','general','maybe',\n",
    "                'collection','book-club','library-book','personal-library','library-books','books-i-have','shelfari-favorites',\n",
    "                'tbr','ya','want','owned-unread','and','next','reread','mine','favorite','owned-to-read','to-re-read',\n",
    "                'read-in-2010','1','read-2013','shelfari-wishlist','shelved','to-get','wanted','read-2017','owned-to-read',\n",
    "                'novel','need-to-buy','sci-fi-to-read','my-collection','read-2014','on-hold','all-time-favorites','my-collection','want-to-read',\n",
    "                'read-2015','want-to-read','my-collection','read-2014','read-2018','read-in-2013','other','borrowed','stories','speculative-fiction',\n",
    "                'finished','to-read-fantasy','to-read-owned','collections','science-fantasy','fantasy-fiction','fantasy-science-fiction',\n",
    "                'fantasy-sci-fi','sci-fi-fantasy','scifi-fantasy','science-fiction-fantasy','science-fiction-and-fantasy','sf-fantasy','sf-f',\n",
    "                'sci-fi-and-fantasy','fantasy-scifi','high-fantasy','fantasy-sf','fantasy','on-my-shelf','fiction-science-fiction',\n",
    "                'ebook','kindle','ebooks','series','audiobook', 'audiobooks', 'adult','e-book','abandoned','adult-fiction','read-in-english',\n",
    "                'young-adult','4-stars','5-stars','favorite-series','science-fiction-romance', 'hardcover', 'kindle-books', 'children','my-bookshelf',\n",
    "                'audio','e-books'\n",
    "               ]\n",
    "# Remove all genere from shelves which are in exclude_item\n",
    "shelves = [ elem for elem in shelves if elem not in exclude_item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adventure 4897\n",
      "romance 4062\n",
      "paranormal 3712\n",
      "dnf 3438\n",
      "audible 3005\n"
     ]
    }
   ],
   "source": [
    "# Check top 10 genres\n",
    "count = Counter(shelves)\n",
    "for genre, frequency in count.most_common(5):\n",
    "    print(genre,frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details['classics']   = np.where(df_details['popular_shelves'].apply(lambda x: sum(i in {'classics','classic','literary','epic'} for i in x.split(\",\"))), True,False)\n",
    "df_details['thriller']   = np.where(df_details['popular_shelves'].apply(lambda x: sum(i in {'mystery','suspense','mystery-suspense','thriller','thrillers','mystery-thriller','crime','mysteries','horror-thriller','suspense-thriller','thriller-suspense','detective','romantic-suspense'} for i in x.split(\",\"))), True,False)\n",
    "df_details['romance']    = np.where(df_details['popular_shelves'].apply(lambda x: sum(i in {'romance','love','paranormal-romance','romance-paranormal','erotic-romance','erotic','erotica','contemporary-romance','sci-fi-romance','scifi-romance','fantasy-romance','alien-romance','m-m-romance','love-triangle','ya-romance','adult-romance','futuristic-romance','romantic-suspense','romance-sci-fi','historical-romance'} for i in x.split(\",\"))), True,False)\n",
    "df_details['paranormal'] = np.where(df_details['popular_shelves'].apply(lambda x: sum(i in {'paranormal','supernatural','vampire','vampires','vamps','zombies','zombie','witches','paranormal-fantasy','paranormal-urban-fantasy','romance-paranormal','fantasy-paranormal','ya-paranormal','adult-paranormal','paranormal-supernatural'} for i in x.split(\",\"))), True,False)\n",
    "df_details['humour']     = np.where(df_details['popular_shelves'].apply(lambda x: sum(i in {'humour','funny','fun','humorous','comedy','humor'} for i in x.split(\",\"))), True,False)\n",
    "df_details['dystopian']  = np.where(df_details['popular_shelves'].apply(lambda x: sum(i in {'dystopian','dystopia','dystopian-post-apocalyptic','dystopian-fiction','dystopias','distopian','distopia','dystopia-utopia','ya-dystopia','dystopian-apocalyptic'} for i in x.split(\",\"))), True,False)\n",
    "df_details['historical'] = np.where(df_details['popular_shelves'].apply(lambda x: sum(i in {'history','historical','historical-fiction','historical-fantasy','historical-romance'} for i in x.split(\",\"))), True,False)\n",
    "df_details['comics']     = np.where(df_details['popular_shelves'].apply(lambda x: sum(i in {'comics','comic','comix','comic-fantasy','graphic-novels','comics-graphic-novels','graphic','graphic-novels-comics','comic-books','comics-and-graphic-novels','graphic-novels-and-comics','comics-manga','read-comics','comics-read','comic-book','comic-graphic-novel','graphicnovels','comics-and-manga','graphic-novel-comic','comics-to-read','manga-graphic-novels','c√≥mics','graphic-novels-comic-books','comic-books-graphic-novels','illustrated','read-graphic-novels'} for i in x.split(\",\"))), True,False)\n",
    "del df_details['popular_shelves']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Create Bag of words for Book Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to lower case\n",
    "df_details[\"word_list\"] = df_details[\"book_description\"].str.lower()\n",
    "# remove html tags\n",
    "cleantags = re.compile('<.*?>')\n",
    "df_details[\"word_list\"] = df_details[\"word_list\"].str.replace(cleantags,' ')\n",
    "# Remove punctuations\n",
    "df_details[\"word_list\"] = df_details[\"word_list\"].str.replace('[^\\w\\s]',' ')\n",
    "# Remove trailing spaces\n",
    "df_details[\"word_list\"] = df_details[\"word_list\"].str.strip()\n",
    "# Remove spaces in between words\n",
    "df_details[\"word_list\"] = df_details[\"word_list\"].str.replace(' +', ' ')\n",
    "# Remove Numbers\n",
    "df_details[\"word_list\"] = df_details[\"word_list\"].str.replace('\\d+', '')\n",
    "# remove stop words\n",
    "stop = stopwords.words('english')\n",
    "stop.extend([\"classics\",\"thriller\",\"horror\",\"romance\",\"paranormal\",\"humour\",\"dystopian\",\"historical\"])\n",
    "df_details[\"word_list\"] =  df_details[\"word_list\"].apply(lambda x: \" \".join(x for x in x.split() if x not in stop ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "df_details[\"word_list\"] = df_details[\"word_list\"].str.strip().str.split('[\\W_]+')\n",
    "# Stemming\n",
    "df_details[\"word_list\"] = [[st.stem(word) for word in words]for words in df_details[\"word_list\"]]\n",
    "#Lemmatization\n",
    "df_details[\"word_list\"] = [[Word(word).lemmatize() for word in words]for words in df_details[\"word_list\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at a clean preprocessed tokenized data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Candidia Maria Smith-Foster, an eleven-year-old girl, is unaware that she's a Homo post hominem, mankind's next evolutionary step. <br /><br />With international relations rapidly deteriorating, Candy's father, publicly a small-town pathologist but secretly a government biowarfare expert, is called to Washington. Candy remains at home.<br /><br />The following day a worldwide attack, featuring a bionuclear plague, wipes out virtually all of humanity (i.e., Homo sapiens). With her pet bird Terry, she survives the attack in the shelter beneath their house. Emerging three months later, she learns of her genetic heritage and sets off to search for others of her kind.\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_details[\"book_description\"][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'candidia maria smith foster eleven year old girl unawar homo post hominem mankind next evolutionari step intern relat rapidli deterior candi father publicli small town pathologist secretli govern biowarfar expert call washington candi remain home follow day worldwid attack featur bionuclear plagu wipe virtual human e homo sapien pet bird terri surviv attack shelter beneath hous emerg three month later learn genet heritag set search other kind'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_details[\"word_list\"][50]\n",
    "\" \".join(df_details[\"word_list\"][50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert a collection of text to a matrix of token counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go simple here:\n",
    "We are using **CountVectorizer** to create a bag of words by specifying **max_df** and **min_df** arguments.\n",
    "- max_df = 0.90 means \"ignore terms that appear in more than 90% of the documents\".\n",
    "- min_df = 50 means \"ignore terms that appear in less than 50 documents\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a CountVectorizer object: count_vect\n",
    "count_vec = CountVectorizer(analyzer='word',tokenizer=lambda doc: doc, lowercase=False, max_df = 0.90, min_df = 50)\n",
    "words_vec = count_vec.fit(df_details[\"word_list\"])\n",
    "bag_of_words = words_vec.transform(df_details[\"word_list\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9576 entries, 0 to 9575\n",
      "Columns: 2207 entries, abandon to zone\n",
      "dtypes: int64(2207)\n",
      "memory usage: 161.2 MB\n"
     ]
    }
   ],
   "source": [
    "tokens = count_vec.get_feature_names()\n",
    "df_words = pd.DataFrame(data=bag_of_words.toarray(),columns=tokens)\n",
    "df_words.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_details = pd.concat([df_details, df_words], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Dataframe for EDA in the next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'df_details' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store df_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
